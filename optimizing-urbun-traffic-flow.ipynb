{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea0b0cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf  # For machine learning\n",
    "from tensorflow.keras.models import Sequential  # For creating neural network models\n",
    "from tensorflow.keras.layers import LSTM, Dense  # For LSTM and Dense layers\n",
    "from sklearn.preprocessing import MinMaxScaler  # For scaling data\n",
    "from sklearn.model_selection import train_test_split  # For splitting data\n",
    "import numpy as np  # For numerical operations\n",
    "import matplotlib.pyplot as plt  # For plotting\n",
    "import seaborn as sns  # For plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8789ec8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Data Preprocessing Module\n",
    "def preprocess_data(data):\n",
    "    \"\"\"\n",
    "    Preprocesses the raw traffic data to make it suitable for machine learning.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): Raw traffic data as a pandas DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Preprocessed traffic data as a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    # 1.1 Handle Missing Values\n",
    "    for col in ['speed', 'volume', 'density']:\n",
    "        if col in data.columns:\n",
    "            data[col].fillna(data[col].mean(), inplace=True)\n",
    "\n",
    "    # 1.2 Convert Timestamp to Datetime\n",
    "    if 'timestamp' in data.columns:\n",
    "        data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "        data['time_of_day'] = data['timestamp'].dt.hour + data['timestamp'].dt.minute / 60\n",
    "        data['day_of_week'] = data['timestamp'].dt.dayofweek\n",
    "\n",
    "    # 1.3 One-Hot Encode Weather Conditions\n",
    "    if 'weather' in data.columns:\n",
    "        data = pd.get_dummies(data, columns=['weather'], dummy_na=False)\n",
    "\n",
    "    # 1.4 Aggregate Data into 5-Minute Intervals\n",
    "    if 'timestamp' in data.columns:\n",
    "        data = data.set_index('timestamp').resample('5Min').agg({\n",
    "            'speed': 'mean',\n",
    "            'volume': 'sum',\n",
    "            'density': 'mean',\n",
    "            'time_of_day': 'mean',\n",
    "            'day_of_week': 'mean'\n",
    "        })\n",
    "        data = data.reset_index()\n",
    "\n",
    "    # 1.5 Feature Engineering: Lagged Volume\n",
    "    if 'volume' in data.columns:\n",
    "        data['volume_lag1'] = data['volume'].shift(1)\n",
    "        data['volume_lag1'].fillna(data['volume'].mean(), inplace=True)\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d1b3717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. LSTM Model for Traffic Flow Prediction\n",
    "def create_lstm_model(input_shape):\n",
    "    \"\"\"\n",
    "    Creates an LSTM model for traffic flow prediction.\n",
    "\n",
    "    Args:\n",
    "        input_shape (tuple): Shape of the input data (time steps, features).\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: LSTM model.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, activation='relu', input_shape=input_shape))\n",
    "    model.add(Dense(1))  # Predict volume\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "def prepare_data_for_lstm(data, target_column='volume', time_steps=12):\n",
    "    \"\"\"\n",
    "    Prepares data for LSTM input.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): Preprocessed traffic data.\n",
    "        target_column (str): Column to predict (e.g., 'volume', 'speed').\n",
    "        time_steps (int): Number of time steps to use for prediction.\n",
    "\n",
    "    Returns:\n",
    "        tuple: X (input sequences), y (target values), scaler (MinMaxScaler).\n",
    "    \"\"\"\n",
    "    data = data.copy()  # Create a copy to avoid modifying the original DataFrame\n",
    "    data_for_scaling = data.drop(columns=['timestamp'])\n",
    "    scaler = MinMaxScaler()\n",
    "    data_scaled = scaler.fit_transform(data_for_scaling.values)\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(time_steps, len(data_scaled)):\n",
    "        X.append(data_scaled[i - time_steps:i])\n",
    "        y.append(\n",
    "            data_scaled[i,\n",
    "                        data_for_scaling.columns.get_loc(target_column)])  # Index by column name\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y, scaler\n",
    "\n",
    "\n",
    "\n",
    "def train_lstm_model(model, X_train, y_train, X_test, y_test, epochs=10, batch_size=32):\n",
    "    \"\"\"\n",
    "    Trains the LSTM model.\n",
    "\n",
    "    Args:\n",
    "        model (tf.keras.Model): LSTM model.\n",
    "        X_train (np.array): Training input data.\n",
    "        y_train (np.array): Training target data.\n",
    "        X_test (np.array): Testing input data.\n",
    "        y_test (np.array): Testing target data.\n",
    "        epochs (int): Number of training epochs.\n",
    "        batch_size (int): Batch size.\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: Trained LSTM model.\n",
    "        history: Training history.\n",
    "    \"\"\"\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size,\n",
    "                        validation_data=(X_test, y_test), verbose=1)\n",
    "    return model, history\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_lstm_model(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluates the LSTM model.\n",
    "\n",
    "    Args:\n",
    "        model (tf.keras.Model): Trained LSTM model.\n",
    "        X_test (np.array): Testing input data.\n",
    "        y_test (np.array): Testing target data.\n",
    "\n",
    "    Returns:\n",
    "        float: Mean Squared Error.\n",
    "    \"\"\"\n",
    "    mse = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "    return mse\n",
    "\n",
    "\n",
    "\n",
    "def predict_traffic_flow(model, data, time_steps, scaler, target_column='volume'):\n",
    "    \"\"\"\n",
    "    Predict traffic flow for the next time step.\n",
    "\n",
    "    Args:\n",
    "        model: Trained prediction model.\n",
    "        data (pd.DataFrame): Current and historical traffic data.\n",
    "        time_steps (int): Number of time steps for prediction.\n",
    "        scaler: MinMaxScaler used to scale the data.\n",
    "        target_column (str): Column to predict\n",
    "\n",
    "    Returns:\n",
    "        float: Predicted traffic volume for the next time step.\n",
    "    \"\"\"\n",
    "    # Prepare the last sequence of data for prediction\n",
    "    # Drop 'timestamp' and 'weather' columns before getting values\n",
    "    last_sequence = data.tail(time_steps).drop(columns=['timestamp', 'weather']).values\n",
    "    last_sequence_scaled = scaler.transform(\n",
    "        last_sequence.reshape(-1, last_sequence.shape[1])).reshape(1, time_steps,\n",
    "                                                        last_sequence.shape[1])\n",
    "    predicted_value_scaled = model.predict(last_sequence_scaled)[0, 0]\n",
    "\n",
    "    # Inverse transform the prediction\n",
    "    dummy_array = np.zeros((1, last_sequence.shape[1])) # Use shape of last_sequence\n",
    "\n",
    "    # Drop 'timestamp' and 'weather' when getting column index\n",
    "    value_index = data.drop(columns=['timestamp', 'weather']).columns.get_loc(target_column)\n",
    "\n",
    "    dummy_array[0, value_index] = predicted_value_scaled\n",
    "    predicted_value = scaler.inverse_transform(dummy_array)[0, value_index]\n",
    "    return predicted_value\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ace677f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Adaptive Traffic Light Control (Conceptual)\n",
    "def adjust_traffic_light_timings(predicted_volume_A, predicted_volume_B, current_timings_A, current_timings_B):\n",
    "    \"\"\"\n",
    "    Adjusts traffic light timings based on predicted traffic volumes for two\n",
    "    approaches (A and B).  This is a simplified example; a real-world system\n",
    "    would be much more complex.\n",
    "\n",
    "    Args:\n",
    "        predicted_volume_A (float): Predicted traffic volume for approach A.\n",
    "        predicted_volume_B (float): Predicted traffic volume for approach B.\n",
    "        current_timings_A (int): Current green light duration for approach A.\n",
    "        current_timings_B (int): Current green light duration for approach B.\n",
    "\n",
    "    Returns:\n",
    "        tuple:  New green light durations for approach A and B.\n",
    "    \"\"\"\n",
    "    # Basic logic: Allocate green time proportionally to predicted volume\n",
    "    total_volume = predicted_volume_A + predicted_volume_B\n",
    "\n",
    "    # Check if total_volume or predicted_volume_A is NaN and handle it\n",
    "    if total_volume == 0 or np.isnan(total_volume) or np.isnan(predicted_volume_A):\n",
    "        return current_timings_A, current_timings_B  # avoid division by zero or NaN\n",
    "\n",
    "    max_green_time = 60  # Maximum green light duration\n",
    "    min_green_time = 10  # Minimum green light duration\n",
    "\n",
    "    new_timings_A = max(min_green_time, min(max_green_time, int(\n",
    "        predicted_volume_A / total_volume * max_green_time)))\n",
    "    new_timings_B = max(min_green_time, min(max_green_time, int(\n",
    "        predicted_volume_B / total_volume * max_green_time)))\n",
    "    return new_timings_A, new_timings_B\n",
    "\n",
    "\n",
    "\n",
    "# 4. Visualization Module\n",
    "def plot_traffic_data(data, title='Traffic Data'):\n",
    "    \"\"\"\n",
    "    Plots the traffic data.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): Traffic data to plot.\n",
    "        title (str): Title of the plot.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    sns.lineplot(data=data, x='timestamp', y='volume', label='Volume')\n",
    "    sns.lineplot(data=data, x='timestamp', y='speed', label='Speed')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Timestamp')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a3e78c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nagen\\AppData\\Local\\Temp\\ipykernel_18920\\661900269.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[col].fillna(data[col].mean(), inplace=True)\n",
      "C:\\Users\\nagen\\AppData\\Local\\Temp\\ipykernel_18920\\661900269.py:41: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['volume_lag1'].fillna(data['volume'].mean(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed Data:\n",
      "            timestamp      speed  volume    density  time_of_day  day_of_week  \\\n",
      "0 2023-01-01 00:00:00  20.987097     191  35.732620     0.000000          6.0   \n",
      "1 2023-01-01 00:05:00  45.488406      52  32.228553     0.083333          6.0   \n",
      "2 2023-01-01 00:10:00  34.845270     147  32.924516     0.166667          6.0   \n",
      "3 2023-01-01 00:15:00  44.623130     200  26.011047     0.250000          6.0   \n",
      "4 2023-01-01 00:20:00  32.945993     205  25.206290     0.333333          6.0   \n",
      "\n",
      "   volume_lag1  \n",
      "0   176.190972  \n",
      "1   191.000000  \n",
      "2    52.000000  \n",
      "3   147.000000  \n",
      "4   200.000000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nagen\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - loss: 0.3588 - val_loss: 0.1785\n",
      "Epoch 2/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - loss: 0.1522 - val_loss: 0.0990\n",
      "Epoch 3/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.1042 - val_loss: 0.1208\n",
      "Epoch 4/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1143 - val_loss: 0.1004\n",
      "Epoch 5/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0972 - val_loss: 0.1008\n",
      "Epoch 6/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0963 - val_loss: 0.1005\n",
      "Epoch 7/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.1023 - val_loss: 0.1008\n",
      "Epoch 8/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0895 - val_loss: 0.1024\n",
      "Epoch 9/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0951 - val_loss: 0.1012\n",
      "Epoch 10/10\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: 0.0942 - val_loss: 0.1003\n",
      "\n",
      "LSTM Model Evaluation:\n",
      "Mean Squared Error: 0.1003\n",
      "\n",
      "Adaptive Traffic Light Control (Conceptual Example):\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 167ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n",
      "Predicted Volume A: nan\n",
      "Predicted Volume B: nan\n",
      "New timings: A = 30s, B = 30s\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the traffic flow prediction and adaptive control system.\n",
    "    \"\"\"\n",
    "    # 1. Data Collection (Simulated Data)\n",
    "    # Generate some sample data for demonstration.  In a real application,\n",
    "    # you would replace this with data from your chosen sources.\n",
    "    data = {\n",
    "        'timestamp': pd.date_range(start='2023-01-01 00:00:00', end='2023-01-01 23:55:00', freq='5min'),\n",
    "        'speed': np.random.uniform(20, 60, 288),  # 288 entries for 5-min intervals in a day\n",
    "        'volume': np.random.randint(50, 300, 288),\n",
    "        'density': np.random.uniform(10, 50, 288),\n",
    "        'weather': np.random.choice(['sunny', 'rainy', 'cloudy'], 288)\n",
    "    }\n",
    "    raw_data = pd.DataFrame(data)\n",
    "\n",
    "    # 2. Data Preprocessing\n",
    "    preprocessed_data = preprocess_data(raw_data)\n",
    "    print(\"Preprocessed Data:\")\n",
    "    print(preprocessed_data.head())\n",
    "\n",
    "    # 3. Prepare Data for LSTM\n",
    "    time_steps = 12  # Use 12 time steps (e.g., 1 hour if data is in 5-min intervals)\n",
    "    target_column = 'volume'  # Column to predict\n",
    "    X, y, scaler = prepare_data_for_lstm(preprocessed_data, time_steps=time_steps, target_column=target_column)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # 4. Train LSTM Model\n",
    "    input_shape = (time_steps, X_train.shape[2])\n",
    "    lstm_model = create_lstm_model(input_shape)\n",
    "    lstm_model, history = train_lstm_model(lstm_model, X_train, y_train, X_test,y_test, epochs=10, batch_size=32)\n",
    "\n",
    "    # 5. Evaluate LSTM Model\n",
    "    print(\"\\nLSTM Model Evaluation:\")\n",
    "    evaluate_lstm_model(lstm_model, X_test, y_test)\n",
    "\n",
    "    # 6. Adaptive Traffic Light Control (Conceptual)\n",
    "    # In a real-world scenario, this would be a continuous loop,\n",
    "    # getting new data, making predictions, and updating timings.\n",
    "    # This is a simplified, single-step example.\n",
    "    print(\"\\nAdaptive Traffic Light Control (Conceptual Example):\")\n",
    "    # Assume we have new data for the current time step\n",
    "    new_data = {\n",
    "        'timestamp': pd.to_datetime('2023-01-02 00:00:00'),\n",
    "        'speed': np.random.uniform(25, 55, 1),\n",
    "        'volume': np.random.randint(60, 280, 1),\n",
    "        'density': np.random.uniform(12, 45, 1),\n",
    "        'weather': np.random.choice(['sunny', 'rainy', 'cloudy'], 1)\n",
    "    }\n",
    "    new_data_df = pd.DataFrame(new_data)\n",
    "    new_data_df['timestamp'] = pd.to_datetime(new_data_df['timestamp'])\n",
    "    current_data = pd.concat([preprocessed_data, new_data_df],\n",
    "                            ignore_index=True)  # Append new data\n",
    "\n",
    "    predicted_volume_A = predict_traffic_flow(lstm_model, current_data,\n",
    "                                                time_steps, scaler,\n",
    "                                                target_column='volume')\n",
    "    predicted_volume_B = predict_traffic_flow(lstm_model, current_data,\n",
    "                                                time_steps, scaler,\n",
    "                                                target_column='volume')  # For simplicity, assume we predict for two approaches\n",
    "\n",
    "    current_timings_A = 30  # Current green time for intersection A\n",
    "    current_timings_B = 30  # Current green time for intersection B\n",
    "\n",
    "    new_timings_A, new_timings_B = adjust_traffic_light_timings(\n",
    "        predicted_volume_A, predicted_volume_B, current_timings_A,\n",
    "        current_timings_B)\n",
    "\n",
    "    print(f\"Predicted Volume A: {predicted_volume_A:.2f}\")\n",
    "    print(f\"Predicted Volume B: {predicted_volume_B:.2f}\")\n",
    "    print(f\"New timings: A = {new_timings_A}s, B = {new_timings_B}s\")\n",
    "    # In a real system, you would send these timings to the traffic light controller\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
